{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnN7T3aOs0clxwuWTI0Bei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonatantussa/gaze-estimation/blob/main/gaze_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2iqjBFUg79H",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install retina-face"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from retinaface import RetinaFace\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "JXQGEdzUiQe3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoGazeAnalyzer:\n",
        "  def __init__(self, use_cuda=True):\n",
        "    self.use_cuda = use_cuda\n",
        "    self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    print(self.device)\n",
        "\n",
        "    self.model, self.transform = torch.hub.load('fkryan/gazelle', 'gazelle_dinov2_vitl14_input', pretrained=True)\n",
        "    self.model.to(self.device)\n",
        "    self.model.eval()\n",
        "\n",
        "    self.colors = ['yellow', 'cyan', 'lime', 'red']\n",
        "\n",
        "  def process_frame(self, frame):\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame_pil = Image.from_array(frame_rgb)\n",
        "\n",
        "    width, height = frame_pil.size\n",
        "\n",
        "    results = RetinaFace.detect_faces(frame_pil)\n",
        "\n",
        "    bboxes = [results[key]['facial_area'] for key in results.keys()]\n",
        "\n",
        "    if not bboxes:\n",
        "      return frame\n",
        "\n",
        "    norm_bboxes = [\n",
        "        [bbox[0] / width, bbox[1] / height, bbox[2] / width, bbox[3] / height]\n",
        "        for bbox in bboxes\n",
        "    ]\n",
        "\n",
        "    img_tensor = self.transform(frame_pil).unsqueeze().to(self.device)\n",
        "\n",
        "    input_data = {'images': img_tensor, 'bboxes': norm_bboxes}\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output = self.mode(input_data)\n",
        "\n",
        "  def visualize_all(self, pil_image, heatmaps, bboxes, input_scores, inpput_thresh=0.5):\n",
        "    \"\"\" Visualize all detected faces and their gaze directions\"\"\"\n",
        "\n",
        "    overlay_image = pil_image.convert(\"RGBA\")"
      ],
      "metadata": {
        "id": "7kRd-ddxibbH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYXLjxC2ih_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}